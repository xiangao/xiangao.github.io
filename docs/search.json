[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "quarto_blog",
    "section": "",
    "text": "Causal simulation\n\n\n\nnews\n\ncode\n\nanalysis\n\n\n\n\n\n\n\n\n\nOct 1, 2025\n\n\nXiang Ao\n\n\n\n\n\n\n\n\n\n\n\n\nlongitudinal modified treatment policy (LMTP)\n\n\n\nR\n\ncode\n\nanalysis\n\n\n\n\n\n\n\n\n\nAug 23, 2025\n\n\nXiang Ao\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts/causal_simulation/index.html",
    "href": "posts/causal_simulation/index.html",
    "title": "Causal simulation",
    "section": "",
    "text": "Evans, R. J., & Didelez, V. (2024). “Parameterizing and simulating from causal models” is about simulating from a causal model. I found that interesting.\nThe usual causal inference is to have a observational data, then assume causal structure, then estimate the parameters. This paper is about the opposite: Suppose we have a causal model, what kind of distribution would generate it?\nSuppose we are interested in joint distribution \\(p(x,a,y)\\), \\(x\\) is covariates, \\(a\\) is treatment, \\(y\\) is outcome.\n\\[\n\\begin{align}\np(x,a,y) &= p(x,a)p(y|x,a) \\\\\n         &= p(x,a)p_a(y|x) \\\\\n         &= p(x,a)\\frac{p_a(x,y)}{p_a(x)} \\\\\n         &= p(x,a)\\frac{p_a(x)p_a(y)c(x,y|a)}{p_a(x)} \\\\\n         &= p(x,a)p_a(y)c(x,y|a)\n\\end{align}\n\\]\nBasically the joint distribution of \\((x,a,y)\\) can be factorized into the marginal distribution of \\((x,a)\\), the conditional distribution of \\(y\\) given \\(x\\) and \\(a\\), and the copula \\(c(x,y|a)\\). The copula is a function that captures the dependence between \\(x\\) and \\(y\\) given \\(a\\). \\((x,a)\\) is the “past”, which can be specified. \\(p_a(y)\\) is the “marginal structure model” which can be specified. The copula model can also be specified.\nAbout copula: copula is a function can link joint distribution to marginal distributions.\n\\[ p(x,y) = f(x)g(y)c(F(x),G(y)) \\]\nwhere \\(F(x)\\) and \\(G(y)\\) are the marginal distributions of \\(x\\) and \\(y\\), respectively, and \\(c\\) is the copula function that captures the dependence between \\(x\\) and \\(y\\). The copula function is a multivariate distribution with uniform marginals. It can be used to generate joint distributions from marginal distributions.\nHere \\(x\\), \\(a\\) and \\(y\\) can all be vectors."
  },
  {
    "objectID": "posts/causal_simulation/index.html#example-1",
    "href": "posts/causal_simulation/index.html#example-1",
    "title": "Causal simulation",
    "section": "example 1",
    "text": "example 1\nSuppose we have a causal graph like this:\n\n\n\n\n\n\n\n\n\nWe need to specify \\(P(y|do(a)) = \\sum_x P(x) P(y|x,a)\\), where \\(P(x)\\) is the marginal distribution of \\(x\\), and \\(P(y|x,a)\\) is the conditional distribution of \\(y\\) given \\(x\\) and \\(a\\). This is the “marginal structural model” (Robins, 2000). Also the “g-formula”.\nWe also need to specify \\(P(x,a)\\), the “past”.\nFinally we need to specify the copula \\(c(x,y|a)\\), which captures the dependence between \\(x\\) and \\(y\\) given \\(a\\). Depending on different situations, different copula can be used.\nIn the “causl” package example, we specify: \\[ X \\sim N(0,1) \\] \\[ A | X=x  \\sim N(x/2, 1) \\] \\[ Y | do(A=a) \\sim N({(a-1)/2}, 1) \\] and Gaussian copula with correlation \\(\\rho = 2 expit(1)-1\\).\n\nlibrary(causl)\n# formulae corresponding to covariates, treatments, outcomes and the dependence\nforms &lt;- list(X ~ 1, A ~ X, Y ~ A, ~ 1)\n# vector of model families (3=gamma/exponential, 1=normal/Gaussian)\nfam &lt;- c(1, 1, 1, 1)\n# list of parameters, including 'beta' (regression params) and 'phi' dispersion\npars &lt;- list(X = list(beta=0, phi=1),   \n             A = list(beta=c(0,0.5), phi=1),\n             Y = list(beta=c(-0.5,0.5), phi=1),\n             cop = list(beta=1))\n\n## now create a `causl_model` object\ncm &lt;- causl_model(formulas=forms, family=fam, pars=pars,method=\"inversion\")\n\n# now simulate 1000 observations\nset.seed(123456)\ndata &lt;- rfrugal(n=1000, causl_model=cm)\nhead(data)\n\n            X           A          Y\n1  0.83373317  1.10709111  1.1416713\n2 -0.27604777 -0.27218853 -1.0495996\n3 -0.35500184  0.77575209  1.3179678\n4  0.08748742 -0.05959823 -0.6106023\n5  2.25225573  0.61909216  2.0789188\n6  0.83446013  0.52019822  0.3229069\n\n\nIn this example, first we specify the structure of the model using a list of formulas. The first formula is for the covariates, the second for the treatments, the third for the outcomes, and the fourth for the dependence structure (copula). Note that outcome \\(Y\\) only depends on \\(A\\) in this interventional distribution.\nThen we specify the families of the random variables. Here we use exponential distribution for \\(X\\), normal distribution for \\(A\\) and \\(Y\\), and Gaussian copula for the dependence structure.\nFinally we specify the parameters of the model, including regression coefficients and dispersion parameters. For example, \\(Y \\sim A\\) has two coefficients, intercept -.5 and slope .5.\nThe causl_model object is then created using these components.\nIn this simple example, if we run a regression with \\(A\\), \\(X\\) in the model, on the simulated data, we would get the correct effect back:\n\nlm1 &lt;- lm(Y ~ A*X, data=data)\nsummary(lm1)\n\n\nCall:\nlm(formula = Y ~ A * X, data = data)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-2.6326 -0.6212 -0.0105  0.6051  3.3132 \n\nCoefficients:\n             Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept) -0.491922   0.030413 -16.175   &lt;2e-16 ***\nA            0.493471   0.027820  17.738   &lt;2e-16 ***\nX            0.468038   0.031878  14.682   &lt;2e-16 ***\nA:X         -0.009247   0.022360  -0.414    0.679    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.8953 on 996 degrees of freedom\nMultiple R-squared:  0.4875,    Adjusted R-squared:  0.4859 \nF-statistic: 315.8 on 3 and 996 DF,  p-value: &lt; 2.2e-16\n\n\nWe can also use MLE:\n\nout &lt;- fit_causl(data, formulas = list(X ~ 1, Y ~ A, ~ 1), family = c(1, 1, 1))\nout\n\nlog-likelihood:  -2716.696 \nX ~ 1\n              est.   s.e. sandwich\n(intercept) 0.0108 0.0314   0.0314\n  residual s.e.:  0.983 0.044 0.0447 \n\nY ~ A\n              est.   s.e. sandwich\n(intercept) -0.491 0.0319   0.0319\nA            0.494 0.0278   0.0295\n  residual s.e.:  1.01 0.0472 0.0475 \n\ncopula parameters:\ncop ~ 1\n             est.  s.e. sandwich\n(intercept) 0.998 0.069   0.0734"
  },
  {
    "objectID": "posts/causal_simulation/index.html#plasmode-simulation",
    "href": "posts/causal_simulation/index.html#plasmode-simulation",
    "title": "Causal simulation",
    "section": "Plasmode simulation",
    "text": "Plasmode simulation\nIn reality, we have a data set and we have a causal model. We want to simulate data from the causal model, but we want the simulated data to have the same distribution as the original data. This is called “plasmode simulation”. For example, we don’t want to use the real outcome variable. In stead, we simulate X’s from the original data, Then simulate Y and A from the causal model. We can then test which method works better in estimating the causal effect of \\(A\\) on \\(Y\\).\n\n\n\nAttaching package: 'dplyr'\n\n\nThe following objects are masked from 'package:stats':\n\n    filter, lag\n\n\nThe following objects are masked from 'package:base':\n\n    intersect, setdiff, setequal, union\n\n\n# A tibble: 4,802 × 58\n     x_1 x_2     x_3   x_4   x_5   x_6   x_7   x_8   x_9  x_10  x_11  x_12  x_13\n   &lt;int&gt; &lt;fct&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt;\n 1    29 C         1     7    60    85     0     0     1     0     0     1     0\n 2    27 C         0     0    64   178     0     0     0     0     0     2     1\n 3    27 C         0     0    60   102     0     0     0     0     0     1     0\n 4    37 C         0     0    65   174     0     0     0     0     0     1     0\n 5    24 C        20    14    63   129     0     0     0     0     0     1     0\n 6    27 C        40    15    63   135     0     0     0     0     0     1     1\n 7    26 C        20     8    69   140     0     0     0     1     0     0     0\n 8    33 C         0     0    60   110     0     0     0     1     0     0     1\n 9    28 C         3     5    61   160     0     0     0     0     0     3     1\n10    31 C         0     0    63   114     0     1     0     0     0     0     0\n# ℹ 4,792 more rows\n# ℹ 45 more variables: x_14 &lt;int&gt;, x_15 &lt;int&gt;, x_16 &lt;int&gt;, x_17 &lt;int&gt;,\n#   x_18 &lt;int&gt;, x_19 &lt;int&gt;, x_20 &lt;int&gt;, x_21 &lt;fct&gt;, x_22 &lt;int&gt;, x_23 &lt;int&gt;,\n#   x_24 &lt;fct&gt;, x_25 &lt;int&gt;, x_26 &lt;int&gt;, x_27 &lt;int&gt;, x_28 &lt;int&gt;, x_29 &lt;int&gt;,\n#   x_30 &lt;int&gt;, x_31 &lt;int&gt;, x_32 &lt;int&gt;, x_33 &lt;int&gt;, x_34 &lt;int&gt;, x_35 &lt;int&gt;,\n#   x_36 &lt;int&gt;, x_37 &lt;int&gt;, x_38 &lt;int&gt;, x_39 &lt;int&gt;, x_40 &lt;int&gt;, x_41 &lt;int&gt;,\n#   x_42 &lt;int&gt;, x_43 &lt;int&gt;, x_44 &lt;int&gt;, x_45 &lt;int&gt;, x_46 &lt;int&gt;, x_47 &lt;int&gt;, …\n\n\n\n# Model for the causal effect of smoking on birthweight\nforms &lt;- list(list(),\n              list(A ~ x_1 + x_3 + x_4),\n              list(Y ~ A),\n              list(~ 1))\n# fams &lt;- list(integer(0), 5, 1, 1)\nfams &lt;- list(integer(0), \"binomial\", \"gaussian\", 1)\npars &lt;- list(A = list(beta=c(-1.5,0.03,0.02,0.05)),\n             Y = list(beta=c(3200, -500), phi=400^2),\n             cop = list(beta=-1))\n\ncm2 &lt;- causl_model(formulas=forms, family=fams, pars=pars, dat = dat)\n \nset.seed(123456)\ndata2 &lt;- rfrugal(causl_model=cm2)\nhead(data2)\n\n  x_1 x_2 x_3 x_4 x_5 x_6 x_7 x_8 x_9 x_10 x_11 x_12 x_13 x_14 x_15 x_16 x_17\n1  29   C   1   7  60  85   0   0   1    0    0    1    0    0    2    0    0\n2  27   C   0   0  64 178   0   0   0    0    0    2    1    0    2    0    0\n3  27   C   0   0  60 102   0   0   0    0    0    1    0    0    0    0    0\n4  37   C   0   0  65 174   0   0   0    0    0    1    0    0    1    0    0\n5  24   C  20  14  63 129   0   0   0    0    0    1    0    0    0    0    0\n6  27   C  40  15  63 135   0   0   0    0    0    1    1    2    2    0    0\n  x_18 x_19 x_20 x_21 x_22 x_23 x_24 x_25 x_26 x_27 x_28 x_29 x_30 x_31 x_32\n1   12   35   10    J    1   43    B   17   64  105   30   11    0    0    0\n2   12   75   12    J    1   50    E   12   90  183   40    8    0    0    0\n3   12   35   10    J    1   57    E   14   70  121   27   12    0    0    0\n4   11   35   12    J    1   43    E   10   80  185   39   10    0    0    0\n5    9   35   15    J    1   33    E   14   70  160   28    7    0    0    0\n6    9   45   10    J    1   40    E   15   64  160   31    9    0    0    0\n  x_33 x_34 x_35 x_36 x_37 x_38 x_39 x_40 x_41 x_42 x_43 x_44 x_45 x_46 x_47\n1    0   79   28  340   48    1    9    9    3    0    3   54   16    0    0\n2    0   69   30  430   73    0    9    9    3    0    5   51   16    0    0\n3    0   84   29  450   76    0    3    6    2    0    4   41   13    0    0\n4    0   82   30  440   78    1    8    9    2    0    8   70   16    0    0\n5    1   85   35  360   71    1    5    8    0    2    3   65   18    0    0\n6    1   81   28  515   56    1    7    9    2    0    1   63   20    0    0\n  x_48 x_49 x_50 x_51 x_52 x_53 x_54 x_55 x_56 x_57 x_58 A        Y\n1    0    0    0    0    0    0    0    0    0   45   39 1 2125.677\n2    0    0    0    0    0    0    0    0    0   46   42 1 2688.990\n3    0    1    0    0    0    0    0    0    0   45   40 0 3442.924\n4    0    0    0    0    0    0    0    0    0   47   40 0 3212.584\n5    0    2    0    0    0    0    0    0    0   47   43 0 2992.775\n6    0    0    0    0    0    0    0    0    0   45   44 0 2738.893\n\n# we can also use rfrugalParam(), which is older version of rfrugal().\n#datAY &lt;- rfrugalParam(formulas=forms, family=fams, pars=pars, dat=dat)\n\nIn this specification, we have a binary treatment \\(A\\) and a continuous outcome \\(Y\\). The covariates are \\(x_1\\), \\(x_3\\) and \\(x_4\\). The copula is a Gaussian copula with correlation -1. We can then simulate the data."
  },
  {
    "objectID": "posts/lmtp/index.html",
    "href": "posts/lmtp/index.html",
    "title": "longitudinal modified treatment policy (LMTP)",
    "section": "",
    "text": "I read a few papers with longitudinal modified treatment policy (LMTP), and found it interesting. It has been used in epidemiology and biostatistics, but I have not seen it in applied econometrics yet.\nHere I am mostly following Nicholas Williams: https://beyondtheate.com/\nWe are usually interested in ATE, the average treatment effect. However, there could be more complicated situations that the treatment is continuous, or the treatment is multivalued, or the treatment is time-varying. The static interventions have problems. For example, the hyphothetical interventions that treatment applies to everyone might be inconceivable. Or such intervention could make positivity assumption fail.\nSuppose we have such a DAG:\nlibrary(ggplot2)\nlibrary(ggdag)\n\ng &lt;- dagify(\n  A1 ~ L1,\n  L2 ~ L1,\n  L2 ~ A1,\n  A2 ~ A1,\n  A2 ~ L2,\n  Y ~ A2,\n  Y ~ L2,\n  Y ~ A1,\n  exposure = \"A2\",\n  outcome = \"Y\",\n  coords = list(x = c(L1 = 1,  L2 = 2, Y = 3, A1 = 1.5, A2 = 2.5),\n                y = c(L1 = 1,  L2 = 1, Y = 1, A1 = 1.5, A2 = 1.5))\n)\n\nggdag(g) + \n  theme_dag()\nWe have multiple time points, and the treatment \\(A\\) is time-varying. We are interested in not only the ATE of \\(A_2\\) on \\(Y\\), but also some other hypothetical interventions."
  },
  {
    "objectID": "posts/lmtp/index.html#assumptions",
    "href": "posts/lmtp/index.html#assumptions",
    "title": "longitudinal modified treatment policy (LMTP)",
    "section": "Assumptions",
    "text": "Assumptions\n\nPositivity. Basically if there is a unit with \\(a_t\\) and \\(h_t\\), then there is a unit with \\(d(a_t, h_t)\\) and \\(h_t\\).\nSequential unconfoundedness. There is no unmeasured confounders."
  },
  {
    "objectID": "posts/lmtp/index.html#dynamic-treatment-regime",
    "href": "posts/lmtp/index.html#dynamic-treatment-regime",
    "title": "longitudinal modified treatment policy (LMTP)",
    "section": "dynamic treatment regime",
    "text": "dynamic treatment regime\nSome notations commonly used in this literature: We observe \\(Z = (L_0, A_0, L_1, A_1, Y)\\), where \\(L\\) is the observed confounder, \\(A\\) is the treatment, and \\(Y\\) is the outcome. The treatment \\(A\\) can be time-varying. We can also have multiple treatments at different time points. For example, we can have \\(A_2\\), \\(A_3\\), etc. In this graph, baseline \\(L_0\\) affects \\(A_0\\), which in turn affects \\(L_1\\), which then affects \\(A_1\\), and finally \\(A_1\\) affects the outcome \\(Y\\).\nHistory \\(H_t\\) is the history of data up to time \\(t\\), right before \\(A_t\\). for example, \\(H_1 = (L_0, A_0, L_1)\\), and \\(H_2 = (L_0, A_0, L_1, A_1)\\). \\(d\\) is the hypothetical intervention function, or shift function, which is a function of the history \\(H_t\\) and the treatment \\(A_t\\). For example, \\(d_0(a_0,h_0,\\epsilon_0)\\) is a user-given function to map \\(a_0\\), \\(h_0\\), and \\(\\epsilon_0\\) to a potential treatment value. The function \\(d\\) can be deterministic, or it can be stochastic. Then we can replace \\(A_0\\) with \\(A_0^d = d_0(A_0, H_0, \\epsilon_0)\\). Then after that \\(A_1(A_0^d)\\) is called the natural value of treatment.\nThis is very general, comparing to the static treatment regime.\nSuppose treatment \\(A\\) is a function of the history of treatment and confounders, for example, \\(A = d(A_1, L_1, A_2, L_2)\\). \\(A\\) can be set to a fixed value, say 1 or 0, or some value \\(A^d\\). This function \\(d\\) can be anything, it can be taking a deterministic value, or it can be a function that takes the natural treatment value \\(A\\) as input. In the package “lmtp”, this is called a shift function, or hypothetical intervention. For example, \\(d\\) can be set to 1 if \\(age &lt; 30\\), or \\(d\\) can be set to double the natural value of \\(A\\). Many possibilities.\nIn comparison, for ATE, we only need to set \\(A\\) to 0 or 1.\nUnder this LMTP, the causal parameter is\n\\[ \\theta = E[Y^{\\bar A^d}] \\]\n\\(Y^{\\bar A^d}\\) is the potential outcome under the hypothetical intervention \\(\\bar A^d\\). At time 1, \\(A^d_1 = d(A_1,H_1)\\)."
  },
  {
    "objectID": "posts/lmtp/index.html#modified-treatment-policy",
    "href": "posts/lmtp/index.html#modified-treatment-policy",
    "title": "longitudinal modified treatment policy (LMTP)",
    "section": "modified treatment policy",
    "text": "modified treatment policy\nLet’s look at a simulated data set to see how exactly we can estimate it.\nThis simulation is from Susmann et al. (2024) “Longitudinal Generalizations of the Average Treatment Effect on the Treated for Multi-valued and Continuous Treatments”. I modified slightly to fit the DAG above.\n\nlibrary(tidyverse)\nlibrary(tidyr)\n\nmtp &lt;- function(data, trt) {\n  a &lt;- data[[trt]]\n  a * 0 + 1\n}\nsimulate_data &lt;- function(seed, N, tau, sigma = 0.5) {\n  set.seed(seed)\n  \n  data &lt;- tibble(id = 1:N)\n  \n  for(t in 1:tau) {\n    Lt &lt;- paste0(\"L_\", t)\n    Ltd &lt;- paste0(\"L_\", t, \"d\")\n    \n    At &lt;- paste0(\"A_\", t)\n    Atd &lt;- paste0(\"A_\", t, \"d\")\n    \n    Lt1 &lt;- paste0(\"L_\", t - 1)\n    Lt1d &lt;- paste0(\"L_\", t - 1, \"d\")\n    \n    At1 &lt;- paste0(\"A_\", t - 1)\n    At1d &lt;- paste0(\"A_\", t - 1, \"d\")\n    \n    if(t == 1) {\n      data[[Lt]] &lt;- runif(N, 0, 1)\n      data[[Ltd]] &lt;- data[[Lt]]\n      \n      data[[At]] &lt;- rbinom(N, size = 1, prob = 0.5)\n    } \n    else {\n      data[[Lt]] &lt;- rnorm(N, mean = 0.25 * data[[Lt1]], 0.5)\n      data[[Ltd]] &lt;- rnorm(N, mean = 0.25 * data[[Lt1d]], 0.5)\n      \n      data[[At]] &lt;- rbinom(N, size = 1, prob = plogis(0.5 - 0.2 * data[[At1]] + 0.1 * data[[Lt1]]))\n    }\n    \n    data[[Atd]] &lt;- mtp(data, At)\n  }\n  data$Y  &lt;- rnorm(N, data[[At]] + data[[Lt]], sigma)\n  data$Yd &lt;- rnorm(N, data[[Atd]] + data[[Ltd]], sigma)\n  data\n}\n\nsimulated_data1 &lt;- simulate_data(seed = 123, N = 10000, tau = 2)\n\nmean(simulated_data1$Yd)\n\n[1] 1.128593\n\nmtp &lt;- function(data, trt) {\n  a &lt;- data[[trt]]\n  a * 0 + 0\n}\n\nsimulated_data2 &lt;- simulate_data(seed = 123, N = 1000, tau = 2)\n\nmean(simulated_data2$Yd)\n\n[1] 0.114403\n\nmean(simulated_data1$Yd) - mean(simulated_data2$Yd)\n\n[1] 1.01419\n\n\nNote in this simulation the variables ending with “d” are the variables under hypothetical intervention, or modified treatment policy. \\(L_1\\) is from \\(uniform(0,1)\\), and \\(L_2\\) is from \\(N(0.25 * L_1, 0.5)\\). The treatment \\(A_1\\) is from a Bernoulli distribution with probability 0.5, and the treatment \\(A_2\\) is from a Bernoulli distribution with probability \\(plogis(0.5 - 0.2 * A_1 + 0.1 * L_2)\\). The outcome \\(Y\\) is from a normal distribution with mean \\(A2 + L2\\). In the simulated data, the modified treatment policy is to set the treatment to 0, then 1. The difference would be SATE.\nIn this case, we can just do a linear regression to get the effect of A2 on Y, knowing the exact DAG.\n\nm1 &lt;- glm(Y ~ L_2 + A_1   + A_2, data = simulated_data1)\nsummary(m1)\n\n\nCall:\nglm(formula = Y ~ L_2 + A_1 + A_2, data = simulated_data1)\n\nCoefficients:\n              Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept) -3.453e-05  9.615e-03  -0.004    0.997    \nL_2          9.998e-01  9.889e-03 101.103   &lt;2e-16 ***\nA_1         -6.042e-03  1.001e-02  -0.604    0.546    \nA_2          1.000e+00  1.027e-02  97.380   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for gaussian family taken to be 0.2500364)\n\n    Null deviance: 7400.0  on 9999  degrees of freedom\nResidual deviance: 2499.4  on 9996  degrees of freedom\nAIC: 14523\n\nNumber of Fisher Scoring iterations: 2\n\n\nLet’s try a different MTP: set half of the time to 0, the other half remain unchanged.\n\\[\nd(a_t, \\epsilon_t) = \\begin{cases}\n    0, & \\text{if } \\epsilon_t &lt; .5 \\ and \\ a_t =1 \\\\\n    a_t, & \\text{otherwise}\n\\end{cases}\n\\]\nThis is, say, to set half of smokers to non-smokers, and the other half remain smokers.\n\n# mtp &lt;- function(data, trt) {\n#   a &lt;- data[[trt]]\n#   epsilon &lt;- rbinom(nrow(data), size = 1, prob = 0.5)\n#   ifelse(epsilon &lt;.5 & a == 1, 0, a)\n# }\nd &lt;- function(a) {\n  epsilon &lt;- runif(length(a))\n  ifelse(epsilon &lt; 0.5 & a == 1, 0, a)\n}\nsimulated_data1$m3_d &lt;- simulated_data1$Y \n\nm2 &lt;- glm(m3_d ~ L_1 + A_1 + L_2 + A_2, data = simulated_data1)\nsummary(m2)\n\n\nCall:\nglm(formula = m3_d ~ L_1 + A_1 + L_2 + A_2, data = simulated_data1)\n\nCoefficients:\n             Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept) -0.005815   0.012842  -0.453    0.651    \nL_1          0.011964   0.017621   0.679    0.497    \nA_1         -0.005956   0.010012  -0.595    0.552    \nL_2          0.998831   0.009987 100.015   &lt;2e-16 ***\nA_2          0.999873   0.010273  97.334   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for gaussian family taken to be 0.2500499)\n\n    Null deviance: 7400.0  on 9999  degrees of freedom\nResidual deviance: 2499.2  on 9995  degrees of freedom\nAIC: 14525\n\nNumber of Fisher Scoring iterations: 2\n\nsimulated_data1$m2_d &lt;- predict(m2, mutate(simulated_data1, A_2 = d(A_2)))\n\nm1 &lt;- glm(m2_d ~ L_1 + A_1, data = simulated_data1)\nsummary(m1)\n\n\nCall:\nglm(formula = m2_d ~ L_1 + A_1, data = simulated_data1)\n\nCoefficients:\n             Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  0.277598   0.015072  18.418   &lt;2e-16 ***\nL_1          0.289658   0.023474  12.339   &lt;2e-16 ***\nA_1         -0.008247   0.013462  -0.613     0.54    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for gaussian family taken to be 0.4528119)\n\n    Null deviance: 4596.0  on 9999  degrees of freedom\nResidual deviance: 4526.8  on 9997  degrees of freedom\nAIC: 20461\n\nNumber of Fisher Scoring iterations: 2\n\nm1_d &lt;- predict(m1, mutate(simulated_data1, A_1 = d(A_1)))\nmean(m1_d)\n\n[1] 0.4197166\n\n\nNote this recursive process is based on Diaz, et al. (2023) “Nonparametric Causal Effects Based on Longitudinal Modified Treatment Policies”.\nHere is how exactly we estimate it: we start with the last time point. Regress it on previous treatment and confounders, and then get the predicted value with \\(A\\) changed based on the MTP. Regress that predicted value on the previous treatment and confounders, get predicted values with \\(A\\) changed based on MTP. Repeat until the first time point. The average of the predicted value at time 1 is the expected value under this MTP.\nThis is basically g-formula extended to longitudinal data.\nIn a general case, this is the generalized g-formula to estimate \\(\\theta\\):\nSet \\(m_{\\tau + 1} = Y\\), let \\(A_t^d = d(A_t, H_t)\\). For \\(t = \\tau, \\ldots, 1\\), recursively define:\n\\[ m_t : (a_t, h_t)  = E[m_{t + 1} (A_{t+1}^d, H_{t+1}) | A_t = a_t, H_t =h_t] \\]\nThen \\(\\theta = E[m_1(A_1^d, L_1)]\\).\nWe start from the last period. Regress \\(m_{\\tau + 1}\\), which is \\(Y\\) on \\(A_{\\tau}\\) and \\(H_{\\tau}\\). Then get the predicted value with \\(A_{\\tau}\\) changed based on the MTP. Then regress that predicted value on \\(A_{\\tau - 1}\\) and \\(H_{\\tau - 1}\\). Repeat until the first time point. The average of the predicted value at time 1 is the expected value under this MTP."
  },
  {
    "objectID": "posts/lmtp/index.html#estimators",
    "href": "posts/lmtp/index.html#estimators",
    "title": "longitudinal modified treatment policy (LMTP)",
    "section": "Estimators",
    "text": "Estimators\nThe authors advocate two estimators, TMLE and SDR (sequentially doubly robust estimatro). The procedures are the same, starting from the last time point, then apply TMLE or SDR, iterate to the first time point."
  },
  {
    "objectID": "posts/lmtp/index.html#shift-function-1",
    "href": "posts/lmtp/index.html#shift-function-1",
    "title": "longitudinal modified treatment policy (LMTP)",
    "section": "shift function 1",
    "text": "shift function 1\nConsider a shift function that assigns meal replacement to all observations at time 1, but only meal replacement at time 2 to those observations whose 4-month BMI is greater than 30.\n\nlibrary(DynTxRegime)\ndata(bmiData)\nbmi &lt;- bmiData\nglimpse(bmi)\n\nRows: 210\nColumns: 8\n$ gender      &lt;int&gt; 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1…\n$ race        &lt;int&gt; 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0…\n$ parentBMI   &lt;dbl&gt; 31.59683, 30.17564, 30.27918, 27.49256, 26.42350, 29.30970…\n$ baselineBMI &lt;dbl&gt; 35.84005, 37.30396, 36.83889, 36.70679, 34.84207, 36.68640…\n$ month4BMI   &lt;dbl&gt; 34.22717, 36.38014, 34.42168, 32.52011, 33.72922, 32.06622…\n$ month12BMI  &lt;dbl&gt; 34.27263, 36.38401, 34.41447, 32.52397, 33.73546, 32.15977…\n$ A1          &lt;chr&gt; \"CD\", \"CD\", \"MR\", \"CD\", \"CD\", \"MR\", \"CD\", \"CD\", \"CD\", \"CD\"…\n$ A2          &lt;chr&gt; \"MR\", \"MR\", \"CD\", \"CD\", \"CD\", \"MR\", \"MR\", \"CD\", \"MR\", \"MR\"…\n\nd_dtr &lt;- function(data, trt) {\n  if (trt == \"A1\") return(rep(\"MR\", nrow(data)))\n  \n  ifelse(data$month4BMI &gt; 30, \"MR\", \"CD\")\n}\n\nfit_dtr &lt;- lmtp_sdr(\n  data = bmi, \n  trt = c(\"A1\", \"A2\"), \n  outcome = \"month12BMI\", \n  baseline = c(\"gender\", \"race\", \"parentBMI\"), \n  time_vary = list(\"baselineBMI\", \"month4BMI\"),\n  shift = d_dtr, \n  outcome_type = \"continuous\",\n  folds = 1,\n  learners_trt = \"SL.glm\", \n  learners_outcome = c(\"SL.mean\", \"SL.glm\", \"SL.gam\")\n)\n\nfit_dtr\n::: {.cell-output .cell-output-stdout}\n      Estimate: 35.853\n    Std. error: 0.362\n\n:::"
  },
  {
    "objectID": "posts/lmtp/index.html#shift-function-2",
    "href": "posts/lmtp/index.html#shift-function-2",
    "title": "longitudinal modified treatment policy (LMTP)",
    "section": "shift function 2",
    "text": "shift function 2\nSuppose we are interested in comparing the dynamic treatment regime to a static treatment regime where all patients receive meal replacement at both time points. Using the SDR estimator, estimate the effect of this static intervention.\nfit_MR &lt;- lmtp_sdr(\n  data = bmi, \n  trt = c(\"A1\", \"A2\"), \n  outcome = \"month12BMI\", \n  baseline = c(\"gender\", \"race\", \"parentBMI\"), \n  time_vary = list(\"baselineBMI\", \"month4BMI\"),\n  shift = \\(data, trt) rep(\"MR\", nrow(data)), \n  outcome_type = \"continuous\",\n  folds = 1,\n  learners_trt = \"SL.glm\", \n  learners_outcome = c(\"SL.mean\", \"SL.glm\", \"SL.gam\")\n)\n\nfit_MR\nLMTP Estimator: SDR\nTrt. Policy: (function(data, trt) rep(\"MR\", nrow(data)))\n\n── Population intervention estimate ──\n\n  Estimate: 35.831\nStd. error: 0.361\n95% Conf. int.: 35.123, 36.539\nLet’s also estimate the effect of an intervention where all patients receive a calorie deficit diet at both time points.\nfit_CD &lt;- lmtp_sdr(\n  data = bmi, \n  trt = c(\"A1\", \"A2\"), \n  outcome = \"month12BMI\", \n  baseline = c(\"gender\", \"race\", \"parentBMI\"), \n  time_vary = list(\"baselineBMI\", \"month4BMI\"),\n  shift = \\(data, trt) rep(\"CD\", nrow(data)), \n  outcome_type = \"continuous\",\n  folds = 1,\n  learners_trt = \"SL.glm\", \n  learners_outcome = c(\"SL.mean\", \"SL.glm\", \"SL.gam\")\n)\n\nfit_CD\nLMTP Estimator: SDR\nTrt. Policy: (function(data, trt) rep(\"CD\", nrow(data)))\n\n── Population intervention estimate ──\n\n  Estimate: 35.053\nStd. error: 0.301\n95% Conf. int.: 34.463, 35.643\nFinally, we can compare the three treatment regimes using the lmtp_contrast function.\n\nlmtp_contrast(fit_dtr, fit_MR, ref = fit_CD)\n::: {.cell-output .cell-output-stdout}\n\n  shift  ref estimate std.error conf.low conf.high p.value\n1  35.9 35.1    0.801     0.335    0.144      1.46  0.0169\n2  35.8 35.1    0.778     0.335    0.122      1.43  0.0201\n\n:::"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this blog"
  }
]