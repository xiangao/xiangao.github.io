{"title":"Causal Inference with Graphical Models","markdown":{"yaml":{"title":"Causal Inference with Graphical Models"},"containsRefs":false,"markdown":"\n\n\n\n\nBroadly speaking, in causal inference we are interested in using data from observational studies (as opposed to randomized controlled trials), in order to answer questions of the following form -- What is the causal effect of setting via an **intervention** (possibly contrary to fact) some variable $A$ to value $a$ on some outcome $Y.$ That is, causal inference concerns itself with the expression of counterfactual distributions obtained from observational distributions through the process of interventions. Causal effects may sometimes be determined using randomized controlled trials (RCTs), but these are often expensive or unethical -- think forcing a random portion of the population to smoke to determine the effect of smoking on lung cancer. Also note that RCTs themselves may be subject to all kinds of messiness such as missing data and dropout from clinical trials so that even if data from an RCT were available, causal inference helps eliminate bias in the estimate of the causal effect arising from such messiness.\n\nThe goal of causal inference then is to determine whether such causal effects can be teased out from purely observational data or messy data. When such counterfactual quantities can be written as functions of the observed data, they are said to be **identified**. Not all causal effects can be identified, but many can -- if we impose enough assumptions on the observed data distribution. Assumptions then, is the price we pay for identifiability, and so being transparent about our assumptions when making causal claims is paramount. This is where **graphical models** allow us to concisely, and intuitively state our set of assumptions. In the words of Miguel Hernán, \"Graphical models allow us to draw our assumptions before our conclusions.\"\n\nA graph ${\\cal G}$ is defined by a set of vertices $V$ and edges that could be directed (e.g., $X \\rightarrow$ Y) interpreted as $X$ being a direct cause of $Y$, bidirected (e.g., $X \\leftrightarrow Y$) interpreted as the existence of unmeasured common causes of both $X$ and $Y$ ($X \\leftarrow U \\rightarrow Y$), or undirected (e.g., $X - Y$) interpreted as a symmetric relationship between $X$ and $Y$. In Ananke, we currently support acyclic graphical models i.e., we do not allow for cyclic causality. So how exactly do graphs help us encode assumptions? Consider the **Directed Acyclic Graph (DAG)** below.\n\n\n\nAll interventional distributions in causal models of a DAG are identified by application of the [g-formula](https://core.ac.uk/download/pdf/82537972.pdf). For example, $p(Y|{\\rm do}(a))$ written as $p(Y(a))$ in potential outcomes notation which we will use more commonly here, is identified as $$p(Y(a))=\\sum_{C, M}p(Y|M, C)p(M|A)p(C)|_{A=a}.$$ But as alluded to earlier, this comes at a price. The assumption made by a DAG (in addition to conditional independence constraints that can be read off by the graphical criterion of d-separation) is that of causal sufficiency, i.e., the absence of bidirected edges assumes the absence of unmeasured common causes. If we are unwilling to assume causal sufficiency, we can impose generalized independence constraints given by [Nested Markov models](https://arxiv.org/pdf/1701.06686.pdf) of an **Acyclic Directed Mixed Graph (ADMG)** representing marginals of DAG models. The ADMG corresponding to the scenario where $C$ is unobserved is shown below.\n\nIn this case $p(Y(a))$ is still identified but not all interventional distributions of an ADMG are identified. A sound and complete algorithm for identification in ADMGs is known due to [Tian and Pearl](http://new.aaai.org/Papers/AAAI/2002/AAAI02-085.pdf), and [Shpitser and Pearl](https://ftp.cs.ucla.edu/pub/stat_ser/r327.pdf). In Ananke, we use a purely [graphical formulation](https://arxiv.org/pdf/1701.06686.pdf) of the aforementioned works that uses the fixing operation ($\\phi$) on nested Markov models, in order to answer identification queries. The following is an example of identification using Ananke for the front-door graph shown above.\n\nAnother implicit assumption made in the above examples was that our data consisted of independent and identically distributed (iid) samples. **Chain Graphs (CGs)**, consisting of directed and undirected edges such that there are no partially directed cycles, have emerged as a popular graphical model of **interference** (a violation of the independence assumption). Consider a scenario in which our population consists of dyads (say couples) capable of influencing each others outcomes. This may be depicted as shown below.\n\nAll interventional distributions of a CG are identified by a [CG version](https://www.jstor.org/stable/pdf/3088778.pdf?refreqid=excelsior%3A8042bfde904f401034faca7093a951c9) of the g-formula. Note however, that chain graphs assume causal sufficiency (lack of bidirected edges). If we'd like to further relax this assumption, we use **Segregated Graphs (SGs)**. Once again, if we do not observe $C$s in the CG shown above, we obtain the SG below. A sound and complete algorithm for identification in SGs was provided by [Sherman and Shpitser](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6330046/pdf/nihms-1001697.pdf).\n\nWe end this section by providing a hierarchy of graphical models (shown below). Two of the models in this hierarchy -- bidirected graphs (BGs), and undirected graphs (UGs) are often not considered by themselves in causal analysis but are building blocks of more complicated graphical models that are, as reflected in the graph hierarchy. At the top of the hierarchy, are SGs comprised of directed, bidirected, and undirected edges. An SG with no undirected edges is an ADMG, and an SG with no bidirected edges is a CG. A BG is an ADMG with no directed edges, and a UG is a CG with no directed edges. Finally, a DAG is an ADMG with no bidirected edges _or_ alternatively a CG with no undirected edges. As we go further up in the hierarchy we relax more assumptions, but identification theory becomes trickier, and so does estimation. For example, a generalized likelihood for BGs, ADMGs, and SGs is not known.\n","srcMarkdownNoYaml":"\n\n\n\n\nBroadly speaking, in causal inference we are interested in using data from observational studies (as opposed to randomized controlled trials), in order to answer questions of the following form -- What is the causal effect of setting via an **intervention** (possibly contrary to fact) some variable $A$ to value $a$ on some outcome $Y.$ That is, causal inference concerns itself with the expression of counterfactual distributions obtained from observational distributions through the process of interventions. Causal effects may sometimes be determined using randomized controlled trials (RCTs), but these are often expensive or unethical -- think forcing a random portion of the population to smoke to determine the effect of smoking on lung cancer. Also note that RCTs themselves may be subject to all kinds of messiness such as missing data and dropout from clinical trials so that even if data from an RCT were available, causal inference helps eliminate bias in the estimate of the causal effect arising from such messiness.\n\nThe goal of causal inference then is to determine whether such causal effects can be teased out from purely observational data or messy data. When such counterfactual quantities can be written as functions of the observed data, they are said to be **identified**. Not all causal effects can be identified, but many can -- if we impose enough assumptions on the observed data distribution. Assumptions then, is the price we pay for identifiability, and so being transparent about our assumptions when making causal claims is paramount. This is where **graphical models** allow us to concisely, and intuitively state our set of assumptions. In the words of Miguel Hernán, \"Graphical models allow us to draw our assumptions before our conclusions.\"\n\nA graph ${\\cal G}$ is defined by a set of vertices $V$ and edges that could be directed (e.g., $X \\rightarrow$ Y) interpreted as $X$ being a direct cause of $Y$, bidirected (e.g., $X \\leftrightarrow Y$) interpreted as the existence of unmeasured common causes of both $X$ and $Y$ ($X \\leftarrow U \\rightarrow Y$), or undirected (e.g., $X - Y$) interpreted as a symmetric relationship between $X$ and $Y$. In Ananke, we currently support acyclic graphical models i.e., we do not allow for cyclic causality. So how exactly do graphs help us encode assumptions? Consider the **Directed Acyclic Graph (DAG)** below.\n\n\n\nAll interventional distributions in causal models of a DAG are identified by application of the [g-formula](https://core.ac.uk/download/pdf/82537972.pdf). For example, $p(Y|{\\rm do}(a))$ written as $p(Y(a))$ in potential outcomes notation which we will use more commonly here, is identified as $$p(Y(a))=\\sum_{C, M}p(Y|M, C)p(M|A)p(C)|_{A=a}.$$ But as alluded to earlier, this comes at a price. The assumption made by a DAG (in addition to conditional independence constraints that can be read off by the graphical criterion of d-separation) is that of causal sufficiency, i.e., the absence of bidirected edges assumes the absence of unmeasured common causes. If we are unwilling to assume causal sufficiency, we can impose generalized independence constraints given by [Nested Markov models](https://arxiv.org/pdf/1701.06686.pdf) of an **Acyclic Directed Mixed Graph (ADMG)** representing marginals of DAG models. The ADMG corresponding to the scenario where $C$ is unobserved is shown below.\n\nIn this case $p(Y(a))$ is still identified but not all interventional distributions of an ADMG are identified. A sound and complete algorithm for identification in ADMGs is known due to [Tian and Pearl](http://new.aaai.org/Papers/AAAI/2002/AAAI02-085.pdf), and [Shpitser and Pearl](https://ftp.cs.ucla.edu/pub/stat_ser/r327.pdf). In Ananke, we use a purely [graphical formulation](https://arxiv.org/pdf/1701.06686.pdf) of the aforementioned works that uses the fixing operation ($\\phi$) on nested Markov models, in order to answer identification queries. The following is an example of identification using Ananke for the front-door graph shown above.\n\nAnother implicit assumption made in the above examples was that our data consisted of independent and identically distributed (iid) samples. **Chain Graphs (CGs)**, consisting of directed and undirected edges such that there are no partially directed cycles, have emerged as a popular graphical model of **interference** (a violation of the independence assumption). Consider a scenario in which our population consists of dyads (say couples) capable of influencing each others outcomes. This may be depicted as shown below.\n\nAll interventional distributions of a CG are identified by a [CG version](https://www.jstor.org/stable/pdf/3088778.pdf?refreqid=excelsior%3A8042bfde904f401034faca7093a951c9) of the g-formula. Note however, that chain graphs assume causal sufficiency (lack of bidirected edges). If we'd like to further relax this assumption, we use **Segregated Graphs (SGs)**. Once again, if we do not observe $C$s in the CG shown above, we obtain the SG below. A sound and complete algorithm for identification in SGs was provided by [Sherman and Shpitser](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6330046/pdf/nihms-1001697.pdf).\n\nWe end this section by providing a hierarchy of graphical models (shown below). Two of the models in this hierarchy -- bidirected graphs (BGs), and undirected graphs (UGs) are often not considered by themselves in causal analysis but are building blocks of more complicated graphical models that are, as reflected in the graph hierarchy. At the top of the hierarchy, are SGs comprised of directed, bidirected, and undirected edges. An SG with no undirected edges is an ADMG, and an SG with no bidirected edges is a CG. A BG is an ADMG with no directed edges, and a UG is a CG with no directed edges. Finally, a DAG is an ADMG with no bidirected edges _or_ alternatively a CG with no undirected edges. As we go further up in the hierarchy we relax more assumptions, but identification theory becomes trickier, and so does estimation. For example, a generalized likelihood for BGs, ADMGs, and SGs is not known.\n"},"formats":{"html":{"identifier":{"display-name":"HTML","target-format":"html","base-format":"html"},"execute":{"fig-width":7,"fig-height":5,"fig-format":"retina","fig-dpi":96,"df-print":"default","error":false,"eval":true,"cache":null,"freeze":false,"echo":true,"output":true,"warning":true,"include":true,"keep-md":false,"keep-ipynb":false,"ipynb":null,"enabled":false,"daemon":null,"daemon-restart":false,"debug":false,"ipynb-filters":[],"ipynb-shell-interactivity":null,"plotly-connected":true,"engine":"jupyter"},"render":{"keep-tex":false,"keep-typ":false,"keep-source":false,"keep-hidden":false,"prefer-html":false,"output-divs":true,"output-ext":"html","fig-align":"default","fig-pos":null,"fig-env":null,"code-fold":"none","code-overflow":"scroll","code-link":false,"code-line-numbers":false,"code-tools":false,"tbl-colwidths":"auto","merge-includes":true,"inline-includes":false,"preserve-yaml":false,"latex-auto-mk":true,"latex-auto-install":true,"latex-clean":true,"latex-min-runs":1,"latex-max-runs":10,"latex-makeindex":"makeindex","latex-makeindex-opts":[],"latex-tlmgr-opts":[],"latex-input-paths":[],"latex-output-dir":null,"link-external-icon":false,"link-external-newwindow":false,"self-contained-math":false,"format-resources":[],"notebook-links":true},"pandoc":{"standalone":true,"wrap":"none","default-image-extension":"png","to":"html","css":["../../../../../styles.css"],"output-file":"causal_graphs.html"},"language":{"toc-title-document":"Table of contents","toc-title-website":"On this page","related-formats-title":"Other Formats","related-notebooks-title":"Notebooks","source-notebooks-prefix":"Source","other-links-title":"Other Links","code-links-title":"Code Links","launch-dev-container-title":"Launch Dev Container","launch-binder-title":"Launch Binder","article-notebook-label":"Article Notebook","notebook-preview-download":"Download Notebook","notebook-preview-download-src":"Download Source","notebook-preview-back":"Back to Article","manuscript-meca-bundle":"MECA Bundle","section-title-abstract":"Abstract","section-title-appendices":"Appendices","section-title-footnotes":"Footnotes","section-title-references":"References","section-title-reuse":"Reuse","section-title-copyright":"Copyright","section-title-citation":"Citation","appendix-attribution-cite-as":"For attribution, please cite this work as:","appendix-attribution-bibtex":"BibTeX citation:","appendix-view-license":"View License","title-block-author-single":"Author","title-block-author-plural":"Authors","title-block-affiliation-single":"Affiliation","title-block-affiliation-plural":"Affiliations","title-block-published":"Published","title-block-modified":"Modified","title-block-keywords":"Keywords","callout-tip-title":"Tip","callout-note-title":"Note","callout-warning-title":"Warning","callout-important-title":"Important","callout-caution-title":"Caution","code-summary":"Code","code-tools-menu-caption":"Code","code-tools-show-all-code":"Show All Code","code-tools-hide-all-code":"Hide All Code","code-tools-view-source":"View Source","code-tools-source-code":"Source Code","tools-share":"Share","tools-download":"Download","code-line":"Line","code-lines":"Lines","copy-button-tooltip":"Copy to Clipboard","copy-button-tooltip-success":"Copied!","repo-action-links-edit":"Edit this page","repo-action-links-source":"View source","repo-action-links-issue":"Report an issue","back-to-top":"Back to top","search-no-results-text":"No results","search-matching-documents-text":"matching documents","search-copy-link-title":"Copy link to search","search-hide-matches-text":"Hide additional matches","search-more-match-text":"more match in this document","search-more-matches-text":"more matches in this document","search-clear-button-title":"Clear","search-text-placeholder":"","search-detached-cancel-button-title":"Cancel","search-submit-button-title":"Submit","search-label":"Search","toggle-section":"Toggle section","toggle-sidebar":"Toggle sidebar navigation","toggle-dark-mode":"Toggle dark mode","toggle-reader-mode":"Toggle reader mode","toggle-navigation":"Toggle navigation","crossref-fig-title":"Figure","crossref-tbl-title":"Table","crossref-lst-title":"Listing","crossref-thm-title":"Theorem","crossref-lem-title":"Lemma","crossref-cor-title":"Corollary","crossref-prp-title":"Proposition","crossref-cnj-title":"Conjecture","crossref-def-title":"Definition","crossref-exm-title":"Example","crossref-exr-title":"Exercise","crossref-ch-prefix":"Chapter","crossref-apx-prefix":"Appendix","crossref-sec-prefix":"Section","crossref-eq-prefix":"Equation","crossref-lof-title":"List of Figures","crossref-lot-title":"List of Tables","crossref-lol-title":"List of Listings","environment-proof-title":"Proof","environment-remark-title":"Remark","environment-solution-title":"Solution","listing-page-order-by":"Order By","listing-page-order-by-default":"Default","listing-page-order-by-date-asc":"Oldest","listing-page-order-by-date-desc":"Newest","listing-page-order-by-number-desc":"High to Low","listing-page-order-by-number-asc":"Low to High","listing-page-field-date":"Date","listing-page-field-title":"Title","listing-page-field-description":"Description","listing-page-field-author":"Author","listing-page-field-filename":"File Name","listing-page-field-filemodified":"Modified","listing-page-field-subtitle":"Subtitle","listing-page-field-readingtime":"Reading Time","listing-page-field-wordcount":"Word Count","listing-page-field-categories":"Categories","listing-page-minutes-compact":"{0} min","listing-page-category-all":"All","listing-page-no-matches":"No matching items","listing-page-words":"{0} words","listing-page-filter":"Filter","draft":"Draft"},"metadata":{"lang":"en","fig-responsive":true,"quarto-version":"1.7.32","editor":"visual","theme":["cosmo","brand"],"title":"Causal Inference with Graphical Models"},"extensions":{"book":{"multiFile":true}}}},"projectFormats":["html"]}