{
  "hash": "83dc7d533992e343ac073d1de96e461e",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Causal simulation\"\nauthor: \"Xiang Ao\"\ndate: \"2025-10-01\"\ncategories: [news, code, analysis]\n\n---\n\n\nEvans, R. J., & Didelez, V. (2024). \"Parameterizing and simulating from causal models\" is about simulating from a causal model.  I found that interesting.\n\nThe usual causal inference is to have a observational data, then assume causal structure, then estimate the parameters.  This paper is about the opposite:  Suppose we have a causal model, what kind of distribution would generate it?\n\nSuppose we are interested in joint distribution $p(x,a,y)$, $x$ is covariates, $a$ is treatment, $y$ is outcome.\n\n\n$$ \n\\begin{align}\np(x,a,y) &= p(x,a)p(y|x,a) \\\\\n         &= p(x,a)p_a(y|x) \\\\\n         &= p(x,a)\\frac{p_a(x,y)}{p_a(x)} \\\\\n         &= p(x,a)\\frac{p_a(x)p_a(y)c(x,y|a)}{p_a(x)} \\\\\n         &= p(x,a)p_a(y)c(x,y|a)\n\\end{align}\n$$\n\nBasically the joint distribution of $(x,a,y)$ can be factorized into the marginal distribution of $(x,a)$, the conditional distribution of $y$ given $x$ and $a$, and the copula $c(x,y|a)$.  The copula is a function that captures the dependence between $x$ and $y$ given $a$.  $(x,a)$ is the \"past\", which can be specified.  $p_a(y)$ is the \"marginal structure model\" which can be specified.  The copula model can also be specified.\n\nAbout copula:  copula is a function can link joint distribution to marginal distributions.  \n\n$$ p(x,y) = f(x)g(y)c(F(x),G(y)) $$\n\nwhere $F(x)$ and $G(y)$ are the marginal distributions of $x$ and $y$, respectively, and $c$ is the copula function that captures the dependence between $x$ and $y$.  The copula function is a multivariate distribution with uniform marginals.  It can be used to generate joint distributions from marginal distributions.\n\nHere $x$, $a$ and $y$ can all be vectors.\n\n# examples\n\nWhat do we use this for?  We can use this to simulate data from a causal model, and then fit different models to the simulated data.  This allows to compare the performance of different models.  \n\n## example 1\n\nSuppose we have a causal graph like this:\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](index_files/figure-html/dag1-1.png){width=672}\n:::\n:::\n\n\nWe need to specify $P(y|do(a)) = \\sum_x P(x) P(y|x,a)$, where $P(x)$ is the marginal distribution of $x$, and $P(y|x,a)$ is the conditional distribution of $y$ given $x$ and $a$.  This is the \"marginal structural model\" (Robins, 2000).  Also the \"g-formula\".  \n\nWe also need to specify $P(x,a)$, the \"past\".\n\nFinally we need to specify the copula $c(x,y|a)$, which captures the dependence between $x$ and $y$ given $a$. Depending on different situations, different copula can be used.\n\nIn the \"causl\" package example, we specify:\n$$ X \\sim N(0,1) $$\n$$ A | X=x  \\sim N(x/2, 1) $$\n$$ Y | do(A=a) \\sim N({(a-1)/2}, 1) $$\nand Gaussian copula with correlation $\\rho = 2 expit(1)-1$.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(causl)\n# formulae corresponding to covariates, treatments, outcomes and the dependence\nforms <- list(X ~ 1, A ~ X, Y ~ A, ~ 1)\n# vector of model families (3=gamma/exponential, 1=normal/Gaussian)\nfam <- c(1, 1, 1, 1)\n# list of parameters, including 'beta' (regression params) and 'phi' dispersion\npars <- list(X = list(beta=0, phi=1),   \n             A = list(beta=c(0,0.5), phi=1),\n             Y = list(beta=c(-0.5,0.5), phi=1),\n             cop = list(beta=1))\n\n## now create a `causl_model` object\ncm <- causl_model(formulas=forms, family=fam, pars=pars,method=\"inversion\")\n\n# now simulate 1000 observations\nset.seed(123456)\ndata <- rfrugal(n=1000, causl_model=cm)\nhead(data)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n            X           A          Y\n1  0.83373317  1.10709111  1.1416713\n2 -0.27604777 -0.27218853 -1.0495996\n3 -0.35500184  0.77575209  1.3179678\n4  0.08748742 -0.05959823 -0.6106023\n5  2.25225573  0.61909216  2.0789188\n6  0.83446013  0.52019822  0.3229069\n```\n\n\n:::\n:::\n\n\nIn this example, first we specify the structure of the model using a list of formulas.  The first formula is for the covariates, the second for the treatments, the third for the outcomes, and the fourth for the dependence structure (copula).  Note that outcome $Y$ only depends on $A$ in this interventional distribution.\n\nThen we specify the families of the random variables.  Here we use exponential distribution for $X$, normal distribution for $A$ and $Y$, and Gaussian copula for the dependence structure.\n\nFinally we specify the parameters of the model, including regression coefficients and dispersion parameters.  For example, $Y \\sim A$ has two coefficients, intercept -.5 and slope .5.  \n\nThe `causl_model` object is then created using these components.\n\nIn this simple example, if we run a regression with $A$, $X$ in the model, on the simulated data, we would get the correct effect back:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlm1 <- lm(Y ~ A*X, data=data)\nsummary(lm1)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nCall:\nlm(formula = Y ~ A * X, data = data)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-2.6326 -0.6212 -0.0105  0.6051  3.3132 \n\nCoefficients:\n             Estimate Std. Error t value Pr(>|t|)    \n(Intercept) -0.491922   0.030413 -16.175   <2e-16 ***\nA            0.493471   0.027820  17.738   <2e-16 ***\nX            0.468038   0.031878  14.682   <2e-16 ***\nA:X         -0.009247   0.022360  -0.414    0.679    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.8953 on 996 degrees of freedom\nMultiple R-squared:  0.4875,\tAdjusted R-squared:  0.4859 \nF-statistic: 315.8 on 3 and 996 DF,  p-value: < 2.2e-16\n```\n\n\n:::\n:::\n\n\nWe can also use MLE:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nout <- fit_causl(data, formulas = list(X ~ 1, Y ~ A, ~ 1), family = c(1, 1, 1))\nout\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nlog-likelihood:  -2716.696 \nX ~ 1\n              est.   s.e. sandwich\n(intercept) 0.0108 0.0314   0.0314\n  residual s.e.:  0.983 0.044 0.0447 \n\nY ~ A\n              est.   s.e. sandwich\n(intercept) -0.491 0.0319   0.0319\nA            0.494 0.0278   0.0295\n  residual s.e.:  1.01 0.0472 0.0475 \n\ncopula parameters:\ncop ~ 1\n             est.  s.e. sandwich\n(intercept) 0.998 0.069   0.0734\n```\n\n\n:::\n:::\n\n\n## Plasmode simulation\n\nIn reality, we have a data set and we have a causal model.  We want to simulate data from the causal model, but we want the simulated data to have the same distribution as the original data.  This is called \"plasmode simulation\".  For example, we don't want to use the real outcome variable.  In stead, we simulate X's from the original data, Then simulate Y and A from the causal model.  We can then test which method works better in estimating the causal effect of $A$ on $Y$.\n\n\n::: {.cell}\n::: {.cell-output .cell-output-stderr}\n\n```\n\nAttaching package: 'dplyr'\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\nThe following objects are masked from 'package:stats':\n\n    filter, lag\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\nThe following objects are masked from 'package:base':\n\n    intersect, setdiff, setequal, union\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 4,802 × 58\n     x_1 x_2     x_3   x_4   x_5   x_6   x_7   x_8   x_9  x_10  x_11  x_12  x_13\n   <int> <fct> <dbl> <dbl> <int> <int> <int> <int> <int> <int> <int> <int> <int>\n 1    29 C         1     7    60    85     0     0     1     0     0     1     0\n 2    27 C         0     0    64   178     0     0     0     0     0     2     1\n 3    27 C         0     0    60   102     0     0     0     0     0     1     0\n 4    37 C         0     0    65   174     0     0     0     0     0     1     0\n 5    24 C        20    14    63   129     0     0     0     0     0     1     0\n 6    27 C        40    15    63   135     0     0     0     0     0     1     1\n 7    26 C        20     8    69   140     0     0     0     1     0     0     0\n 8    33 C         0     0    60   110     0     0     0     1     0     0     1\n 9    28 C         3     5    61   160     0     0     0     0     0     3     1\n10    31 C         0     0    63   114     0     1     0     0     0     0     0\n# ℹ 4,792 more rows\n# ℹ 45 more variables: x_14 <int>, x_15 <int>, x_16 <int>, x_17 <int>,\n#   x_18 <int>, x_19 <int>, x_20 <int>, x_21 <fct>, x_22 <int>, x_23 <int>,\n#   x_24 <fct>, x_25 <int>, x_26 <int>, x_27 <int>, x_28 <int>, x_29 <int>,\n#   x_30 <int>, x_31 <int>, x_32 <int>, x_33 <int>, x_34 <int>, x_35 <int>,\n#   x_36 <int>, x_37 <int>, x_38 <int>, x_39 <int>, x_40 <int>, x_41 <int>,\n#   x_42 <int>, x_43 <int>, x_44 <int>, x_45 <int>, x_46 <int>, x_47 <int>, …\n```\n\n\n:::\n:::\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Model for the causal effect of smoking on birthweight\nforms <- list(list(),\n              list(A ~ x_1 + x_3 + x_4),\n              list(Y ~ A),\n              list(~ 1))\n# fams <- list(integer(0), 5, 1, 1)\nfams <- list(integer(0), \"binomial\", \"gaussian\", 1)\npars <- list(A = list(beta=c(-1.5,0.03,0.02,0.05)),\n             Y = list(beta=c(3200, -500), phi=400^2),\n             cop = list(beta=-1))\n\ncm2 <- causl_model(formulas=forms, family=fams, pars=pars, dat = dat)\n \nset.seed(123456)\ndata2 <- rfrugal(causl_model=cm2)\nhead(data2)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n  x_1 x_2 x_3 x_4 x_5 x_6 x_7 x_8 x_9 x_10 x_11 x_12 x_13 x_14 x_15 x_16 x_17\n1  29   C   1   7  60  85   0   0   1    0    0    1    0    0    2    0    0\n2  27   C   0   0  64 178   0   0   0    0    0    2    1    0    2    0    0\n3  27   C   0   0  60 102   0   0   0    0    0    1    0    0    0    0    0\n4  37   C   0   0  65 174   0   0   0    0    0    1    0    0    1    0    0\n5  24   C  20  14  63 129   0   0   0    0    0    1    0    0    0    0    0\n6  27   C  40  15  63 135   0   0   0    0    0    1    1    2    2    0    0\n  x_18 x_19 x_20 x_21 x_22 x_23 x_24 x_25 x_26 x_27 x_28 x_29 x_30 x_31 x_32\n1   12   35   10    J    1   43    B   17   64  105   30   11    0    0    0\n2   12   75   12    J    1   50    E   12   90  183   40    8    0    0    0\n3   12   35   10    J    1   57    E   14   70  121   27   12    0    0    0\n4   11   35   12    J    1   43    E   10   80  185   39   10    0    0    0\n5    9   35   15    J    1   33    E   14   70  160   28    7    0    0    0\n6    9   45   10    J    1   40    E   15   64  160   31    9    0    0    0\n  x_33 x_34 x_35 x_36 x_37 x_38 x_39 x_40 x_41 x_42 x_43 x_44 x_45 x_46 x_47\n1    0   79   28  340   48    1    9    9    3    0    3   54   16    0    0\n2    0   69   30  430   73    0    9    9    3    0    5   51   16    0    0\n3    0   84   29  450   76    0    3    6    2    0    4   41   13    0    0\n4    0   82   30  440   78    1    8    9    2    0    8   70   16    0    0\n5    1   85   35  360   71    1    5    8    0    2    3   65   18    0    0\n6    1   81   28  515   56    1    7    9    2    0    1   63   20    0    0\n  x_48 x_49 x_50 x_51 x_52 x_53 x_54 x_55 x_56 x_57 x_58 A        Y\n1    0    0    0    0    0    0    0    0    0   45   39 1 2125.677\n2    0    0    0    0    0    0    0    0    0   46   42 1 2688.990\n3    0    1    0    0    0    0    0    0    0   45   40 0 3442.924\n4    0    0    0    0    0    0    0    0    0   47   40 0 3212.584\n5    0    2    0    0    0    0    0    0    0   47   43 0 2992.775\n6    0    0    0    0    0    0    0    0    0   45   44 0 2738.893\n```\n\n\n:::\n\n```{.r .cell-code}\n# we can also use rfrugalParam(), which is older version of rfrugal().\n#datAY <- rfrugalParam(formulas=forms, family=fams, pars=pars, dat=dat)\n```\n:::\n\n\nIn this specification, we have a binary treatment $A$ and a continuous outcome $Y$.  The covariates are $x_1$, $x_3$ and $x_4$.  The copula is a Gaussian copula with correlation -1.  We can then simulate the data.\n\n# a more complicated model\n\nLet's simulate a more complicated model:\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(ggplot2)\nlibrary(ggdag)\n\ng <- dagify(\n  A1 ~ L1,\n  L2 ~ L1,\n  L2 ~ A1,\n  A2 ~ A1,\n  A2 ~ L2,\n  Y ~ A2,\n  Y ~ L2,\n  Y ~ A1,\n  exposure = \"A2\",\n  outcome = \"Y\",\n  coords = list(x = c(L1 = 1,  L2 = 2, Y = 3, A1 = 1.5, A2 = 2.5),\n                y = c(L1 = 1,  L2 = 1, Y = 1, A1 = 1.5, A2 = 1.5))\n)\n\nggdag(g) + \n  theme_dag() \n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/dag2-1.png){width=672}\n:::\n:::\n\nLet's see how to write a causal model:\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# formulae corresponding to covariates, treatments, outcomes and the dependence\nforms <- list(list(L1  ~ 1, L2 ~ L1*A1),   # covariates\n              list(A1 ~ L1, A2 ~ L2*A1), # treatments\n              Y ~ A1*A2*L2,             # outcome\n              ~ 1)\n\n# vector of model families (3=gamma/exponential, 1=normal/Gaussian)\n\nfams <- list(c(1, 1), c(5,5), 1, 1)\npars <- list(L1 = list(beta=0, phi=1),\n             L2 = list(beta=c(0.3,0.5,-0.2,-0.1), phi=1),\n             A1 = list(beta=c(-0.3,0.4), phi=1),\n             A2 = list(beta=c(0.5,0.3,0.1,0), phi=1),\n             Y = list(beta=c(0,1,2,0.5,1,0.2,0,0.8), phi=1), \n             cop = list(beta = 0.5))\n\n# we can use rfrugalParam() to simulate data from the model, or rfrugal().\n#dat <- rfrugalParam(n=1e4, formulas=forms, family = fams, pars=pars)\n#head(dat)\n\ncm3 <- causl_model(formulas=forms, family=fams, pars=pars)\n \nset.seed(123456)\ndata3 <- rfrugal(n=1e4,causl_model=cm3)\nhead(data3)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n           L1          L2 A1 A2         Y\n1  0.83373317  1.91691936  1  1 8.1680612\n2 -0.27604777  0.17008294  1  1 5.2276976\n3 -0.35500184  0.16907708  1  1 2.8194835\n4  0.08748742  0.19688985  0  1 2.6789661\n5  2.25225573 -0.29257431  0  0 0.3180188\n6  0.83446013  0.02661196  0  1 1.5694426\n```\n\n\n:::\n:::\n\n\nIf we have the correct specification for the outcome model, we'll get it right by linear model:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nm1 <- glm(Y ~ A1*A2*L2, data = data3)\nsummary(m1)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nCall:\nglm(formula = Y ~ A1 * A2 * L2, data = data3)\n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept) -0.11524    0.02110  -5.461 4.85e-08 ***\nA1           1.11589    0.03245  34.391  < 2e-16 ***\nA2           2.02332    0.02682  75.454  < 2e-16 ***\nL2           0.80424    0.01929  41.682  < 2e-16 ***\nA1:A2        0.98345    0.04090  24.044  < 2e-16 ***\nA1:L2        0.16028    0.02976   5.386 7.37e-08 ***\nA2:L2       -0.03446    0.02401  -1.435    0.151    \nA1:A2:L2     0.83541    0.03693  22.620  < 2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for gaussian family taken to be 0.9100255)\n\n    Null deviance: 53902  on 9999  degrees of freedom\nResidual deviance:  9093  on 9992  degrees of freedom\nAIC: 27446\n\nNumber of Fisher Scoring iterations: 2\n```\n\n\n:::\n\n```{.r .cell-code}\nlibrary(marginaleffects)\navg_comparisons(\n    model = m1,\n    variables = \"A2\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n Estimate Std. Error   z Pr(>|z|)   S 2.5 % 97.5 %\n     2.51     0.0202 124   <0.001 Inf  2.47   2.55\n\nTerm: A2\nType: response\nComparison: 1 - 0\n```\n\n\n:::\n:::\n\n\nSo the ATE is 2.5.\n\nLet's use \"lmtp\" package to estimate the treatment effect of $A_2$ on $Y$.\n\n```{.r .cell-code}\nlibrary(lmtp)\n\nd1 <- function(data, trt) {\n  rep(1, nrow(data))\n}\nA <- \"A2\"\nY <- \"Y\"\nW <- c(\"L1\", \"L2\", \"A1\")\n\nset.seed(34465)\n\ntreat <- lmtp_tmle(\n  data = data3, \n  trt = \"A2\", \n  outcome = \"Y\", \n  baseline = W, \n  outcome_type = \"continuous\", \n  shift = d1, \n  folds = 1, \n  learners_trt = \"SL.glm\", \n  learners_outcome = \"SL.glm\"\n)\n\nprint(treat)\n```\n\n```\nLMTP Estimator: TMLE\n```\n\n   \n\n```\nTrt. Policy: (d1)\n```\n\n```\n\n```\n\n```\n── Population intervention estimate ──\n```\n\n```\n\n```\n\n      Estimate: 3.046\n    Std. error: 0.022\n\n```\n95% Conf. int.: 3.003, 3.089\n```\n\n```{.r .cell-code}\nd2 <- function(data, trt) {\n  rep(0, nrow(data))\n}\ncontrol <- lmtp_tmle(\n  data = data3, \n  trt = \"A2\", \n  outcome = \"Y\", \n  baseline = W, \n  outcome_type = \"continuous\", \n  shift = d2, \n  folds = 1, \n  learners_trt = \"SL.glm\", \n  learners_outcome = \"SL.glm\"\n)\n\nprint(control)\n```\n\n```\nLMTP Estimator: TMLE\n```\n\n   \n\n```\nTrt. Policy: (d2)\n```\n\n```\n── Population intervention estimate ──\n```\n\n```\n\n```\n\n      Estimate: 0.542\n    Std. error: 0.021\n\n```\n95% Conf. int.: 0.501, 0.582\n```\n\n```{.r .cell-code}\nlmtp_contrast(treat, ref = control)\n```\n\n\n  \n\n```\nLMTP Contrast: additive\n```\n\n```\nNull hypothesis: theta == 0\n```\n\n\n  shift   ref estimate std.error conf.low conf.high p.value\n1  3.05 0.542      2.5    0.0227     2.46      2.55  <0.001\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}